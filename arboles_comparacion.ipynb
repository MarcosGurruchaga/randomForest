{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Comparaci√≥n de √Årboles de Decisi√≥n: 2 vs 3 Caracter√≠sticas\n",
        "\n",
        "Este notebook compara √°rboles de decisi√≥n entrenados con diferentes n√∫meros de caracter√≠sticas para analizar c√≥mo afecta la complejidad y estructura del √°rbol.\n",
        "\n",
        "## Objetivos del An√°lisis\n",
        "\n",
        "1. **Comparar complejidad**: Ver c√≥mo cambia la estructura del √°rbol con m√°s caracter√≠sticas\n",
        "2. **Visualizar nodos**: Mostrar la estructura interna de cada √°rbol\n",
        "3. **Analizar rendimiento**: Comparar precisi√≥n y generalizaci√≥n\n",
        "4. **Entender trade-offs**: Balance entre complejidad y capacidad predictiva\n",
        "\n",
        "## ¬øPor qu√© es importante esta comparaci√≥n?\n",
        "\n",
        "- **Simplicidad vs Precisi√≥n**: M√°s caracter√≠sticas pueden mejorar la precisi√≥n pero aumentar la complejidad\n",
        "- **Interpretabilidad**: √Årboles m√°s simples son m√°s f√°ciles de interpretar\n",
        "- **Overfitting**: M√°s caracter√≠sticas pueden llevar a sobreajuste\n",
        "- **Tiempo de entrenamiento**: M√°s caracter√≠sticas aumentan el tiempo computacional\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Importar las librer√≠as necesarias\n",
        "import numpy as np  # Para operaciones num√©ricas y arrays\n",
        "import pandas as pd  # Para manipulaci√≥n de datos estructurados\n",
        "import matplotlib.pyplot as plt  # Para crear gr√°ficos y visualizaciones\n",
        "import seaborn as sns  # Para gr√°ficos estad√≠sticos m√°s avanzados\n",
        "from sklearn.datasets import make_classification  # Para generar datos sint√©ticos\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree  # Para √°rboles de decisi√≥n y visualizaci√≥n\n",
        "from sklearn.model_selection import train_test_split  # Para dividir datos\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix  # M√©tricas de evaluaci√≥n\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score  # M√©tricas adicionales\n",
        "import warnings  # Para manejar advertencias\n",
        "warnings.filterwarnings('ignore')  # Ignorar advertencias para limpiar la salida\n",
        "\n",
        "# Configurar el estilo de los gr√°ficos\n",
        "plt.style.use('seaborn-v0_8')  # Usar estilo seaborn para gr√°ficos m√°s atractivos\n",
        "sns.set_palette(\"husl\")  # Configurar paleta de colores\n",
        "plt.rcParams['figure.figsize'] = (12, 8)  # Tama√±o por defecto de las figuras\n",
        "\n",
        "print(\"‚úÖ Librer√≠as importadas correctamente\")\n",
        "print(\"üìä Configuraci√≥n de gr√°ficos aplicada\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generar dataset sint√©tico para la comparaci√≥n\n",
        "print(\"üîß Generando dataset sint√©tico...\")\n",
        "\n",
        "# Crear dataset con caracter√≠sticas controladas para la comparaci√≥n\n",
        "X_full, y = make_classification(\n",
        "    n_samples=500,        # 500 muestras totales\n",
        "    n_features=5,         # 5 caracter√≠sticas disponibles\n",
        "    n_informative=3,      # 3 caracter√≠sticas realmente informativas\n",
        "    n_redundant=2,        # 2 caracter√≠sticas redundantes\n",
        "    n_classes=2,          # Problema de clasificaci√≥n binaria\n",
        "    random_state=42       # Semilla para reproducibilidad\n",
        ")\n",
        "\n",
        "# Crear DataFrame para mejor visualizaci√≥n\n",
        "df_full = pd.DataFrame(X_full, columns=[f'Feature_{i+1}' for i in range(X_full.shape[1])])\n",
        "df_full['target'] = y  # Agregar variable objetivo\n",
        "\n",
        "print(\"üìä Informaci√≥n del dataset completo:\")\n",
        "print(f\"   Forma del dataset: {X_full.shape}\")\n",
        "print(f\"   N√∫mero de clases: {len(np.unique(y))}\")\n",
        "print(f\"   Distribuci√≥n de clases: {np.bincount(y)}\")\n",
        "\n",
        "# Mostrar estad√≠sticas b√°sicas\n",
        "print(f\"\\nüìà Estad√≠sticas de las caracter√≠sticas:\")\n",
        "print(df_full.describe().round(3))\n",
        "\n",
        "# Mostrar primeras filas\n",
        "print(f\"\\nüîç Primeras 5 filas del dataset:\")\n",
        "print(df_full.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Preparar datasets con diferentes n√∫meros de caracter√≠sticas\n",
        "print(\"üîß Preparando datasets para comparaci√≥n...\")\n",
        "\n",
        "# Dataset con 2 caracter√≠sticas (las m√°s informativas)\n",
        "X_2_features = X_full[:, :2]  # Tomar solo las primeras 2 caracter√≠sticas\n",
        "feature_names_2 = ['Feature_1', 'Feature_2']  # Nombres de las caracter√≠sticas\n",
        "\n",
        "# Dataset con 3 caracter√≠sticas (las m√°s informativas)\n",
        "X_3_features = X_full[:, :3]  # Tomar las primeras 3 caracter√≠sticas\n",
        "feature_names_3 = ['Feature_1', 'Feature_2', 'Feature_3']  # Nombres de las caracter√≠sticas\n",
        "\n",
        "# Dividir datos en entrenamiento y prueba (usar la misma divisi√≥n para ambos)\n",
        "X_train_2, X_test_2, y_train, y_test = train_test_split(\n",
        "    X_2_features, y, test_size=0.3, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "X_train_3, X_test_3, _, _ = train_test_split(\n",
        "    X_3_features, y, test_size=0.3, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "print(\"üìä Informaci√≥n de los datasets preparados:\")\n",
        "print(f\"   Dataset con 2 caracter√≠sticas:\")\n",
        "print(f\"     - Entrenamiento: {X_train_2.shape}\")\n",
        "print(f\"     - Prueba: {X_test_2.shape}\")\n",
        "print(f\"     - Caracter√≠sticas: {feature_names_2}\")\n",
        "\n",
        "print(f\"\\n   Dataset con 3 caracter√≠sticas:\")\n",
        "print(f\"     - Entrenamiento: {X_train_3.shape}\")\n",
        "print(f\"     - Prueba: {X_test_3.shape}\")\n",
        "print(f\"     - Caracter√≠sticas: {feature_names_3}\")\n",
        "\n",
        "# Verificar que las distribuciones de clases son iguales\n",
        "print(f\"\\n‚úÖ Verificaci√≥n de distribuciones:\")\n",
        "print(f\"   Clases en entrenamiento: {np.bincount(y_train)}\")\n",
        "print(f\"   Clases en prueba: {np.bincount(y_test)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Entrenar √°rboles de decisi√≥n con diferentes n√∫meros de caracter√≠sticas\n",
        "print(\"üå≤ Entrenando √°rboles de decisi√≥n...\")\n",
        "\n",
        "# √Årbol con 2 caracter√≠sticas\n",
        "print(\"\\nüìä Entrenando √°rbol con 2 caracter√≠sticas...\")\n",
        "tree_2_features = DecisionTreeClassifier(\n",
        "    random_state=42,      # Semilla para reproducibilidad\n",
        "    max_depth=None,       # Sin l√≠mite de profundidad para ver estructura completa\n",
        "    min_samples_split=2,  # M√≠nimo de muestras para dividir\n",
        "    min_samples_leaf=1    # M√≠nimo de muestras en hoja\n",
        ")\n",
        "\n",
        "# Entrenar el √°rbol con 2 caracter√≠sticas\n",
        "tree_2_features.fit(X_train_2, y_train)\n",
        "\n",
        "# Hacer predicciones\n",
        "y_pred_2 = tree_2_features.predict(X_test_2)\n",
        "\n",
        "# Calcular m√©tricas\n",
        "accuracy_2 = accuracy_score(y_test, y_pred_2)\n",
        "precision_2 = precision_score(y_test, y_pred_2)\n",
        "recall_2 = recall_score(y_test, y_pred_2)\n",
        "f1_2 = f1_score(y_test, y_pred_2)\n",
        "\n",
        "print(f\"‚úÖ √Årbol con 2 caracter√≠sticas entrenado\")\n",
        "print(f\"   Accuracy: {accuracy_2:.4f}\")\n",
        "print(f\"   Precision: {precision_2:.4f}\")\n",
        "print(f\"   Recall: {recall_2:.4f}\")\n",
        "print(f\"   F1-Score: {f1_2:.4f}\")\n",
        "\n",
        "# √Årbol con 3 caracter√≠sticas\n",
        "print(\"\\nüìä Entrenando √°rbol con 3 caracter√≠sticas...\")\n",
        "tree_3_features = DecisionTreeClassifier(\n",
        "    random_state=42,      # Misma semilla para comparaci√≥n justa\n",
        "    max_depth=None,       # Sin l√≠mite de profundidad\n",
        "    min_samples_split=2,  # Mismos par√°metros que el √°rbol anterior\n",
        "    min_samples_leaf=1\n",
        ")\n",
        "\n",
        "# Entrenar el √°rbol con 3 caracter√≠sticas\n",
        "tree_3_features.fit(X_train_3, y_train)\n",
        "\n",
        "# Hacer predicciones\n",
        "y_pred_3 = tree_3_features.predict(X_test_3)\n",
        "\n",
        "# Calcular m√©tricas\n",
        "accuracy_3 = accuracy_score(y_test, y_pred_3)\n",
        "precision_3 = precision_score(y_test, y_pred_3)\n",
        "recall_3 = recall_score(y_test, y_pred_3)\n",
        "f1_3 = f1_score(y_test, y_pred_3)\n",
        "\n",
        "print(f\"‚úÖ √Årbol con 3 caracter√≠sticas entrenado\")\n",
        "print(f\"   Accuracy: {accuracy_3:.4f}\")\n",
        "print(f\"   Precision: {precision_3:.4f}\")\n",
        "print(f\"   Recall: {recall_3:.4f}\")\n",
        "print(f\"   F1-Score: {f1_3:.4f}\")\n",
        "\n",
        "# Comparaci√≥n r√°pida\n",
        "print(f\"\\nüìà Comparaci√≥n r√°pida:\")\n",
        "print(f\"   Mejora en Accuracy: {accuracy_3 - accuracy_2:.4f}\")\n",
        "print(f\"   Mejora en F1-Score: {f1_3 - f1_2:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# An√°lisis de la estructura de los √°rboles\n",
        "print(\"üîç AN√ÅLISIS DE LA ESTRUCTURA DE LOS √ÅRBOLES\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Obtener informaci√≥n sobre la estructura del √°rbol con 2 caracter√≠sticas\n",
        "depth_2 = tree_2_features.get_depth()  # Profundidad m√°xima del √°rbol\n",
        "n_leaves_2 = tree_2_features.get_n_leaves()  # N√∫mero de hojas\n",
        "n_nodes_2 = tree_2_features.tree_.node_count  # N√∫mero total de nodos\n",
        "\n",
        "print(f\"üå≤ √Årbol con 2 caracter√≠sticas:\")\n",
        "print(f\"   Profundidad m√°xima: {depth_2}\")\n",
        "print(f\"   N√∫mero de hojas: {n_leaves_2}\")\n",
        "print(f\"   N√∫mero total de nodos: {n_nodes_2}\")\n",
        "\n",
        "# Obtener informaci√≥n sobre la estructura del √°rbol con 3 caracter√≠sticas\n",
        "depth_3 = tree_3_features.get_depth()  # Profundidad m√°xima del √°rbol\n",
        "n_leaves_3 = tree_3_features.get_n_leaves()  # N√∫mero de hojas\n",
        "n_nodes_3 = tree_3_features.tree_.node_count  # N√∫mero total de nodos\n",
        "\n",
        "print(f\"\\nüå≤ √Årbol con 3 caracter√≠sticas:\")\n",
        "print(f\"   Profundidad m√°xima: {depth_3}\")\n",
        "print(f\"   N√∫mero de hojas: {n_leaves_3}\")\n",
        "print(f\"   N√∫mero total de nodos: {n_nodes_3}\")\n",
        "\n",
        "# Comparaci√≥n de complejidad\n",
        "print(f\"\\nüìä Comparaci√≥n de complejidad:\")\n",
        "print(f\"   Diferencia en profundidad: {depth_3 - depth_2}\")\n",
        "print(f\"   Diferencia en hojas: {n_leaves_3 - n_leaves_2}\")\n",
        "print(f\"   Diferencia en nodos: {n_nodes_3 - n_nodes_2}\")\n",
        "\n",
        "# Calcular complejidad relativa\n",
        "complexity_ratio_depth = depth_3 / depth_2 if depth_2 > 0 else float('inf')\n",
        "complexity_ratio_leaves = n_leaves_3 / n_leaves_2 if n_leaves_2 > 0 else float('inf')\n",
        "complexity_ratio_nodes = n_nodes_3 / n_nodes_2 if n_nodes_2 > 0 else float('inf')\n",
        "\n",
        "print(f\"\\nüìà Ratios de complejidad (3 features / 2 features):\")\n",
        "print(f\"   Profundidad: {complexity_ratio_depth:.2f}x\")\n",
        "print(f\"   Hojas: {complexity_ratio_leaves:.2f}x\")\n",
        "print(f\"   Nodos: {complexity_ratio_nodes:.2f}x\")\n",
        "\n",
        "# An√°lisis de caracter√≠sticas utilizadas\n",
        "print(f\"\\nüîç Caracter√≠sticas utilizadas:\")\n",
        "print(f\"   √Årbol con 2 caracter√≠sticas: {feature_names_2}\")\n",
        "print(f\"   √Årbol con 3 caracter√≠sticas: {feature_names_3}\")\n",
        "\n",
        "# Obtener importancia de caracter√≠sticas\n",
        "importance_2 = tree_2_features.feature_importances_\n",
        "importance_3 = tree_3_features.feature_importances_\n",
        "\n",
        "print(f\"\\nüìä Importancia de caracter√≠sticas:\")\n",
        "print(f\"   √Årbol con 2 caracter√≠sticas:\")\n",
        "for i, (name, imp) in enumerate(zip(feature_names_2, importance_2)):\n",
        "    print(f\"     {name}: {imp:.4f}\")\n",
        "\n",
        "print(f\"   √Årbol con 3 caracter√≠sticas:\")\n",
        "for i, (name, imp) in enumerate(zip(feature_names_3, importance_3)):\n",
        "    print(f\"     {name}: {imp:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualizaci√≥n de los √°rboles de decisi√≥n\n",
        "print(\"üé® VISUALIZACI√ìN DE LOS √ÅRBOLES DE DECISI√ìN\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Crear figura con dos subplots lado a lado\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 10))  # Figura m√°s grande para mejor visualizaci√≥n\n",
        "\n",
        "# Visualizar √°rbol con 2 caracter√≠sticas\n",
        "print(\"üå≤ Visualizando √°rbol con 2 caracter√≠sticas...\")\n",
        "plot_tree(tree_2_features, \n",
        "          feature_names=feature_names_2,  # Nombres de las caracter√≠sticas\n",
        "          class_names=['Clase 0', 'Clase 1'],  # Nombres de las clases\n",
        "          filled=True,  # Rellenar nodos con colores\n",
        "          rounded=True,  # Bordes redondeados\n",
        "          fontsize=10,  # Tama√±o de fuente\n",
        "          ax=ax1)  # Usar el primer subplot\n",
        "\n",
        "ax1.set_title('√Årbol de Decisi√≥n - 2 Caracter√≠sticas', fontsize=14, fontweight='bold')\n",
        "\n",
        "# Visualizar √°rbol con 3 caracter√≠sticas\n",
        "print(\"üå≤ Visualizando √°rbol con 3 caracter√≠sticas...\")\n",
        "plot_tree(tree_3_features, \n",
        "          feature_names=feature_names_3,  # Nombres de las caracter√≠sticas\n",
        "          class_names=['Clase 0', 'Clase 1'],  # Nombres de las clases\n",
        "          filled=True,  # Rellenar nodos con colores\n",
        "          rounded=True,  # Bordes redondeados\n",
        "          fontsize=10,  # Tama√±o de fuente\n",
        "          ax=ax2)  # Usar el segundo subplot\n",
        "\n",
        "ax2.set_title('√Årbol de Decisi√≥n - 3 Caracter√≠sticas', fontsize=14, fontweight='bold')\n",
        "\n",
        "# Ajustar el espaciado entre subplots\n",
        "plt.tight_layout()\n",
        "plt.show()  # Mostrar la visualizaci√≥n\n",
        "\n",
        "print(\"‚úÖ Visualizaciones completadas\")\n",
        "print(\"\\nüí° Interpretaci√≥n de los gr√°ficos:\")\n",
        "print(\"   ‚Ä¢ Los nodos muestran la condici√≥n de divisi√≥n\")\n",
        "print(\"   ‚Ä¢ Los colores indican la clase predominante\")\n",
        "print(\"   ‚Ä¢ La intensidad del color indica la pureza del nodo\")\n",
        "print(\"   ‚Ä¢ Las hojas muestran la predicci√≥n final\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Comparaci√≥n detallada de rendimiento\n",
        "print(\"üìä COMPARACI√ìN DETALLADA DE RENDIMIENTO\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Crear DataFrame con los resultados\n",
        "comparison_results = pd.DataFrame({\n",
        "    'M√©trica': ['Accuracy', 'Precision', 'Recall', 'F1-Score'],\n",
        "    '2 Caracter√≠sticas': [accuracy_2, precision_2, recall_2, f1_2],\n",
        "    '3 Caracter√≠sticas': [accuracy_3, precision_3, recall_3, f1_3]\n",
        "})\n",
        "\n",
        "# Calcular diferencias\n",
        "comparison_results['Diferencia'] = comparison_results['3 Caracter√≠sticas'] - comparison_results['2 Caracter√≠sticas']\n",
        "comparison_results['Mejora %'] = (comparison_results['Diferencia'] / comparison_results['2 Caracter√≠sticas'] * 100).round(2)\n",
        "\n",
        "print(\"üìà Tabla comparativa de m√©tricas:\")\n",
        "print(comparison_results.round(4))\n",
        "\n",
        "# Visualizaci√≥n de la comparaci√≥n\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 12))  # Crear figura con 4 subplots\n",
        "fig.suptitle('Comparaci√≥n de Rendimiento: 2 vs 3 Caracter√≠sticas', fontsize=16, fontweight='bold')\n",
        "\n",
        "# Gr√°fico 1: Comparaci√≥n de m√©tricas principales\n",
        "metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score']\n",
        "x_pos = np.arange(len(metrics))  # Posiciones en el eje x\n",
        "width = 0.35  # Ancho de las barras\n",
        "\n",
        "axes[0, 0].bar(x_pos - width/2, comparison_results['2 Caracter√≠sticas'], width, \n",
        "               label='2 Caracter√≠sticas', alpha=0.7, color='skyblue')\n",
        "axes[0, 0].bar(x_pos + width/2, comparison_results['3 Caracter√≠sticas'], width, \n",
        "               label='3 Caracter√≠sticas', alpha=0.7, color='lightcoral')\n",
        "axes[0, 0].set_title('Comparaci√≥n de M√©tricas', fontweight='bold')\n",
        "axes[0, 0].set_ylabel('Score')\n",
        "axes[0, 0].set_xticks(x_pos)\n",
        "axes[0, 0].set_xticklabels(metrics, rotation=45)\n",
        "axes[0, 0].legend()\n",
        "axes[0, 0].grid(True, alpha=0.3)\n",
        "\n",
        "# Gr√°fico 2: Mejoras porcentuales\n",
        "axes[0, 1].bar(metrics, comparison_results['Mejora %'], alpha=0.7, color='green')\n",
        "axes[0, 1].set_title('Mejora Porcentual (3 vs 2 Caracter√≠sticas)', fontweight='bold')\n",
        "axes[0, 1].set_ylabel('Mejora (%)')\n",
        "axes[0, 1].tick_params(axis='x', rotation=45)\n",
        "axes[0, 1].grid(True, alpha=0.3)\n",
        "axes[0, 1].axhline(y=0, color='red', linestyle='--', alpha=0.5)  # L√≠nea de referencia en 0%\n",
        "\n",
        "# Gr√°fico 3: Comparaci√≥n de complejidad\n",
        "complexity_metrics = ['Profundidad', 'Hojas', 'Nodos']\n",
        "complexity_2 = [depth_2, n_leaves_2, n_nodes_2]\n",
        "complexity_3 = [depth_3, n_leaves_3, n_nodes_3]\n",
        "\n",
        "x_pos_complexity = np.arange(len(complexity_metrics))\n",
        "axes[1, 0].bar(x_pos_complexity - width/2, complexity_2, width, \n",
        "               label='2 Caracter√≠sticas', alpha=0.7, color='lightgreen')\n",
        "axes[1, 0].bar(x_pos_complexity + width/2, complexity_3, width, \n",
        "               label='3 Caracter√≠sticas', alpha=0.7, color='orange')\n",
        "axes[1, 0].set_title('Comparaci√≥n de Complejidad', fontweight='bold')\n",
        "axes[1, 0].set_ylabel('Cantidad')\n",
        "axes[1, 0].set_xticks(x_pos_complexity)\n",
        "axes[1, 0].set_xticklabels(complexity_metrics)\n",
        "axes[1, 0].legend()\n",
        "axes[1, 0].grid(True, alpha=0.3)\n",
        "\n",
        "# Gr√°fico 4: Importancia de caracter√≠sticas\n",
        "axes[1, 1].bar(feature_names_2, importance_2, alpha=0.7, color='purple', label='2 Caracter√≠sticas')\n",
        "axes[1, 1].bar(feature_names_3, importance_3, alpha=0.7, color='brown', label='3 Caracter√≠sticas')\n",
        "axes[1, 1].set_title('Importancia de Caracter√≠sticas', fontweight='bold')\n",
        "axes[1, 1].set_ylabel('Importancia')\n",
        "axes[1, 1].tick_params(axis='x', rotation=45)\n",
        "axes[1, 1].legend()\n",
        "axes[1, 1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()  # Ajustar espaciado\n",
        "plt.show()  # Mostrar gr√°ficos\n",
        "\n",
        "print(\"‚úÖ An√°lisis de rendimiento completado\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# An√°lisis de matrices de confusi√≥n\n",
        "print(\"üìä AN√ÅLISIS DE MATRICES DE CONFUSI√ìN\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Calcular matrices de confusi√≥n\n",
        "cm_2 = confusion_matrix(y_test, y_pred_2)  # Matriz de confusi√≥n para 2 caracter√≠sticas\n",
        "cm_3 = confusion_matrix(y_test, y_pred_3)  # Matriz de confusi√≥n para 3 caracter√≠sticas\n",
        "\n",
        "# Crear visualizaci√≥n de matrices de confusi√≥n\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))  # Crear figura con 2 subplots\n",
        "\n",
        "# Matriz de confusi√≥n para 2 caracter√≠sticas\n",
        "sns.heatmap(cm_2, annot=True, fmt='d', cmap='Blues',  # Crear heatmap con anotaciones\n",
        "            xticklabels=['Pred 0', 'Pred 1'],  # Etiquetas del eje x\n",
        "            yticklabels=['Real 0', 'Real 1'],  # Etiquetas del eje y\n",
        "            ax=ax1)  # Usar el primer subplot\n",
        "ax1.set_title('Matriz de Confusi√≥n - 2 Caracter√≠sticas', fontweight='bold')\n",
        "ax1.set_xlabel('Predicci√≥n')\n",
        "ax1.set_ylabel('Valor Real')\n",
        "\n",
        "# Matriz de confusi√≥n para 3 caracter√≠sticas\n",
        "sns.heatmap(cm_3, annot=True, fmt='d', cmap='Reds',  # Crear heatmap con anotaciones\n",
        "            xticklabels=['Pred 0', 'Pred 1'],  # Etiquetas del eje x\n",
        "            yticklabels=['Real 0', 'Real 1'],  # Etiquetas del eje y\n",
        "            ax=ax2)  # Usar el segundo subplot\n",
        "ax2.set_title('Matriz de Confusi√≥n - 3 Caracter√≠sticas', fontweight='bold')\n",
        "ax2.set_xlabel('Predicci√≥n')\n",
        "ax2.set_ylabel('Valor Real')\n",
        "\n",
        "plt.tight_layout()  # Ajustar espaciado\n",
        "plt.show()  # Mostrar gr√°ficos\n",
        "\n",
        "# An√°lisis detallado de las matrices de confusi√≥n\n",
        "print(\"\\nüîç An√°lisis detallado de matrices de confusi√≥n:\")\n",
        "\n",
        "# Para el √°rbol con 2 caracter√≠sticas\n",
        "tn_2, fp_2, fn_2, tp_2 = cm_2.ravel()  # Descomponer la matriz de confusi√≥n\n",
        "print(f\"\\nüå≤ √Årbol con 2 caracter√≠sticas:\")\n",
        "print(f\"   Verdaderos Negativos (TN): {tn_2}\")\n",
        "print(f\"   Falsos Positivos (FP): {fp_2}\")\n",
        "print(f\"   Falsos Negativos (FN): {fn_2}\")\n",
        "print(f\"   Verdaderos Positivos (TP): {tp_2}\")\n",
        "\n",
        "# Para el √°rbol con 3 caracter√≠sticas\n",
        "tn_3, fp_3, fn_3, tp_3 = cm_3.ravel()  # Descomponer la matriz de confusi√≥n\n",
        "print(f\"\\nüå≤ √Årbol con 3 caracter√≠sticas:\")\n",
        "print(f\"   Verdaderos Negativos (TN): {tn_3}\")\n",
        "print(f\"   Falsos Positivos (FP): {fp_3}\")\n",
        "print(f\"   Falsos Negativos (FN): {fn_3}\")\n",
        "print(f\"   Verdaderos Positivos (TP): {tp_3}\")\n",
        "\n",
        "# Comparaci√≥n de errores\n",
        "print(f\"\\nüìà Comparaci√≥n de errores:\")\n",
        "print(f\"   Diferencia en Falsos Positivos: {fp_3 - fp_2}\")\n",
        "print(f\"   Diferencia en Falsos Negativos: {fn_3 - fn_2}\")\n",
        "print(f\"   Total de errores (2 caracter√≠sticas): {fp_2 + fn_2}\")\n",
        "print(f\"   Total de errores (3 caracter√≠sticas): {fp_3 + fn_3}\")\n",
        "print(f\"   Diferencia en total de errores: {(fp_3 + fn_3) - (fp_2 + fn_2)}\")\n",
        "\n",
        "# Calcular m√©tricas adicionales\n",
        "specificity_2 = tn_2 / (tn_2 + fp_2) if (tn_2 + fp_2) > 0 else 0  # Especificidad para 2 caracter√≠sticas\n",
        "specificity_3 = tn_3 / (tn_3 + fp_3) if (tn_3 + fp_3) > 0 else 0  # Especificidad para 3 caracter√≠sticas\n",
        "\n",
        "print(f\"\\nüìä M√©tricas adicionales:\")\n",
        "print(f\"   Especificidad (2 caracter√≠sticas): {specificity_2:.4f}\")\n",
        "print(f\"   Especificidad (3 caracter√≠sticas): {specificity_3:.4f}\")\n",
        "print(f\"   Diferencia en especificidad: {specificity_3 - specificity_2:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusiones y An√°lisis Final\n",
        "\n",
        "### üìä Resumen de la Comparaci√≥n\n",
        "\n",
        "En esta comparaci√≥n hemos analizado c√≥mo el n√∫mero de caracter√≠sticas afecta la estructura y rendimiento de los √°rboles de decisi√≥n:\n",
        "\n",
        "#### üå≤ **Estructura de los √Årboles:**\n",
        "- **√Årbol con 2 caracter√≠sticas**: Estructura m√°s simple, menos nodos y menor profundidad\n",
        "- **√Årbol con 3 caracter√≠sticas**: Estructura m√°s compleja, m√°s nodos y mayor profundidad\n",
        "\n",
        "#### üìà **Rendimiento:**\n",
        "- **Precisi√≥n**: El √°rbol con 3 caracter√≠sticas generalmente muestra mejor precisi√≥n\n",
        "- **Complejidad**: Mayor n√∫mero de caracter√≠sticas aumenta la complejidad del modelo\n",
        "- **Interpretabilidad**: Menos caracter√≠sticas hacen el modelo m√°s f√°cil de interpretar\n",
        "\n",
        "### üéØ **Trade-offs Identificados:**\n",
        "\n",
        "#### ‚úÖ **Ventajas de m√°s caracter√≠sticas:**\n",
        "- Mayor capacidad predictiva\n",
        "- Mejor precisi√≥n en muchos casos\n",
        "- M√°s informaci√≥n disponible para las decisiones\n",
        "\n",
        "#### ‚ö†Ô∏è **Desventajas de m√°s caracter√≠sticas:**\n",
        "- Mayor complejidad computacional\n",
        "- Riesgo de overfitting\n",
        "- Menor interpretabilidad\n",
        "- Mayor tiempo de entrenamiento\n",
        "\n",
        "### üí° **Recomendaciones Pr√°cticas:**\n",
        "\n",
        "#### Para **Simplicidad e Interpretabilidad**:\n",
        "- Usar 2 caracter√≠sticas principales\n",
        "- Priorizar caracter√≠sticas m√°s importantes\n",
        "- Aceptar ligera p√©rdida de precisi√≥n por simplicidad\n",
        "\n",
        "#### Para **M√°xima Precisi√≥n**:\n",
        "- Usar 3 o m√°s caracter√≠sticas relevantes\n",
        "- Monitorear overfitting con validaci√≥n cruzada\n",
        "- Considerar regularizaci√≥n si es necesario\n",
        "\n",
        "#### Para **Balance √ìptimo**:\n",
        "- Empezar con 2 caracter√≠sticas principales\n",
        "- Agregar caracter√≠sticas gradualmente\n",
        "- Evaluar mejora marginal vs complejidad adicional\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
